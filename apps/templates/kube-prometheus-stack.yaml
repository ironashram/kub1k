apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
  labels:
    app/cluster: "{{ .Values.environment }}"
    app/source: upstream
spec:
  project: default
  syncPolicy:
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    automated:
      prune: true
      selfHeal: true
  source:
    chart: kube-prometheus-stack
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: 81.4.2
    helm:
      valuesObject:
        kubernetesServiceMonitors:
          enabled: true
        defaultRules:
          rules:
            alertmanager: true
          disabled:
            Watchdog: true
            InfoInhibitor: true
        alertmanager:
          alertmanagerSpec:
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: synology-csi-iscsi-custom
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 10Gi
          config:
            route:
              group_by: ['namespace']
              group_wait: 30s
              group_interval: 5m
              repeat_interval: 12h
              receiver: matrix
            receivers:
              - name: matrix
                webhook_configs:
                  - url: "https://matrix-alertmanager-receiver.{{ .Values.externalDomain }}/alerts/k8s-alerts"
              - name: 'null'
          ingress:
            annotations:
              cert-manager.io/cluster-issuer: letsencrypt-prod
            enabled: true
            ingressClassName: haproxy
            hosts:
              - alertmanager.{{ .Values.internalDomain }}
            tls:
              - secretName: alertmanager-cert
                hosts:
                  - alertmanager.{{ .Values.internalDomain }}
        grafana:
          persistence:
            enabled: true
            type: sts
            storageClassName: synology-csi-iscsi-custom
            accessModes:
              - ReadWriteOnce
            size: 10Gi
            finalizers:
              - kubernetes.io/pvc-protection
          admin:
            existingSecret: grafana-admin
            userKey: admin-user
            passwordKey: admin-password
          ingress:
            annotations:
              cert-manager.io/cluster-issuer: letsencrypt-prod
            enabled: true
            ingressClassName: haproxy
            hosts:
              - grafana.{{ .Values.internalDomain }}
            tls:
              - secretName: grafana-cert
                hosts:
                  - grafana.{{ .Values.internalDomain }}
          serviceMonitor:
            labels:
              release: kube-prometheus-stack
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
                - name: "custom-grafana-dashboards"
                  orgId: 1
                  folder: ""
                  type: file
                  disableDeletion: true
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/custom-grafana-dashboards
          dashboards:
            custom-grafana-dashboards:
              argocd:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/argocd.json
              calico-felix:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/calico-felix.json
              calico-typha:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/calico-typha.json
              haproxy-ingress:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/haproxy-ingress.json
              k8s-system-api-server:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/k8s-system-api-server.json
              k8s-views-global:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/k8s-views-global.json
              k8s-views-namespaces:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/k8s-views-namespaces.json
              k8s-views-nodes:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/k8s-views-nodes.json
              k8s-views-pods:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/k8s-views-pods.json
              metallb:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/metallb.json
              trivy-operator-vulnerabilities:
                url: https://raw.githubusercontent.com/ironashram/kub1k/main/dashboards/trivy.json
        prometheus:
          serviceMonitor:
            relabelings:
              - action: replace
                targetLabel: cluster
                replacement: prometheus
          ingress:
            annotations:
              cert-manager.io/cluster-issuer: letsencrypt-prod
            enabled: true
            ingressClassName: haproxy
            hosts:
              - prometheus.{{ .Values.internalDomain }}
            tls:
              - secretName: prometheus-cert
                hosts:
                  - prometheus.{{ .Values.internalDomain }}
          prometheusSpec:
            enableFeatures:
              - exemplar-storage
            serviceMonitorSelectorNilUsesHelmValues: false
            serviceMonitorNamespaceSelector:
              matchExpressions:
                - key: kubernetes.io/metadata.name
                  operator: Exists
            retention: 45d
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: synology-csi-iscsi-custom
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 50Gi
            nodeSelector:
              node-role.kubernetes.io/worker: "true"
            securityContext:
              runAsUser: 0
              runAsNonRoot: false
              runAsGroup: 0
              fsGroup: 0
            additionalScrapeConfigs:
              - job_name: 'kube-etcd'
                scheme: http
                static_configs:
                  - targets: ['{{ .Values.k8sEndpoint }}:2381']
                metric_relabel_configs:
                  - source_labels: [__name__]
                    regex: (etcd|grpc|rest_client|process|go)_(.+)
                    action: keep
                relabel_configs:
                  - source_labels: []
                    target_label: endpoint
                    replacement: http-metrics
                  - source_labels: []
                    target_label: service
                    replacement: kube-prometheus-stack-kube-etcd
                  - source_labels: []
                    target_label: namespace
                    replacement: kube-system
              - job_name: 'kube-controller-manager'
                scheme: https
                static_configs:
                  - targets: ['{{ .Values.k8sEndpoint }}:10257']
                tls_config:
                  insecure_skip_verify: true
                bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
                metric_relabel_configs:
                  - source_labels: [__name__]
                    regex: (workqueue|rest_client|process|go)_(.+)
                    action: keep
                relabel_configs:
                  - source_labels: []
                    target_label: endpoint
                    replacement: https-metrics
                  - source_labels: []
                    target_label: service
                    replacement: kube-prometheus-stack-kube-controller-manager
                  - source_labels: []
                    target_label: namespace
                    replacement: kube-system
              - job_name: 'kube-scheduler'
                scheme: https
                static_configs:
                  - targets: ['{{ .Values.k8sEndpoint }}:10259']
                tls_config:
                  insecure_skip_verify: true
                bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
                metric_relabel_configs:
                  - source_labels: [__name__]
                    regex: (scheduler|rest_client|process|go)_(.+)
                    action: keep
                relabel_configs:
                  - source_labels: []
                    target_label: endpoint
                    replacement: https-metrics
                  - source_labels: []
                    target_label: service
                    replacement: kube-prometheus-stack-kube-scheduler
                  - source_labels: []
                    target_label: namespace
                    replacement: kube-system
        prometheusOperator:
          tls:
            enabled: false
          admissionWebhooks:
            enabled: false
            failurePolicy: Ignore
        kubeApiServer:
          serviceMonitor:
            metricRelabelings:
              - sourceLabels: ["__name__"]
                regex: "(apiserver|workqueue|rest_client|process|go)_(.+)"
                action: keep
        kubelet:
          serviceMonitor:
            metricRelabelings:
              - sourceLabels: ["__name__"]
                regex: "(kubelet|storage|rest_client|process|go)_(.+)"
                action: keep
        kubeEtcd:
          service:
            enabled: false
          serviceMonitor:
            enabled: false
        kubeControllerManager:
          service:
            enabled: false
          serviceMonitor:
            enabled: false
        kubeScheduler:
          service:
            enabled: false
          serviceMonitor:
            enabled: false
        kubeProxy:
          enabled: false
        coreDns:
          enabled: true
          service:
            enabled: false
          serviceMonitor:
            enabled: false
        additionalPrometheusRulesMap:
          velero:
            groups:
            - name: velero
              rules:
                - alert: VeleroBackupFailed
                  annotations:
                    message: Velero backup {{`{{`}} $labels.schedule {{`}}`}} has failed
                  expr: |-
                    velero_backup_last_status{schedule!=""} != 1
                  for: 15m
                  labels:
                    severity: warning
                - alert: VeleroBackupFailing
                  annotations:
                    message: Velero backup {{`{{`}} $labels.schedule {{`}}`}} has been failing for the last 12h
                  expr: |-
                    velero_backup_last_status{schedule!=""} != 1
                  for: 12h
                  labels:
                    severity: critical
                - alert: VeleroNoNewBackup
                  annotations:
                    message: Velero backup {{`{{`}} $labels.schedule {{`}}`}} has not run successfully in the last 25h
                  expr: |-
                    (
                    (time() - velero_backup_last_successful_timestamp{schedule!=""}) >bool (25 * 3600)
                    or
                    absent(velero_backup_last_successful_timestamp{schedule!=""})
                    ) == 1
                  for: 1h
                  labels:
                    severity: critical
                - alert: VeleroBackupPartialFailures
                  annotations:
                    message: Velero backup {{`{{`}} $labels.schedule {{`}}`}} has {{`{{`}} $value | humanizePercentage {{`}}`}} partialy failed backups
                  expr: |-
                    rate(velero_backup_partial_failure_total{schedule!=""}[25m])
                      / rate(velero_backup_attempt_total{schedule!=""}[25m]) > 0.5
                  for: 15m
                  labels:
                    severity: warning
  ignoreDifferences:
    - group: "apps"
      kind: "Deployment"
      jqPathExpressions:
        - .spec.template.spec.containers[].resources
        - .spec.template.spec.initContainers[].resources
    - group: "apps"
      kind: "DaemonSet"
      jqPathExpressions:
        - .spec.template.spec.containers[].resources
    - group: "apps"
      kind: "StatefulSet"
      jqPathExpressions:
        - .spec.volumeClaimTemplates[]
  destination:
    name: in-cluster
    namespace: monitoring
